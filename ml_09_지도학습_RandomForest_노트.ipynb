{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yK6WkLAmOllo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random  Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMV7K2b0pXrt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 앙상블 학습(Ensemble Learning)\n",
    "\n",
    "- 앙상블(ensemble)은 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만드는 기법\n",
    "\n",
    "- 머신러닝에는 이런 종류의 모델이 많지만, 랜덤 포레스트random forest와 그래디언트 부스팅(gradient boosting) 결정 트리는 둘 다 모델을 구성하는 기본 요소로 결정 트리를 사용 <br>\n",
    "(두 앙상블 모델이 분류와 회귀 문제의 다양한 데이터 셋에서 효과적이라고 입증)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ13NW_IruLJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "앙상블 학습을 통한 분류기\n",
    "\n",
    "- 여러 개의 분류기(Classifier)를 생성하고 그 예측을 결합아여 보다 정확한 최종 예측을 도출하는 기법\n",
    "\n",
    "앙상블 학습의 유형 : 보팅(Voting), 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking)\n",
    "\n",
    "- 보팅(Voting) : 서로 다른 알고리즘을 가진 분류기를 결합\n",
    "- 배깅(Bagging) : 모두 같은 유형의 알고리즘 기반, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행\n",
    "- 부스팅(Boosting) : 여러 개의 분류기가 순차적으로 학습을 수행하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서 올바르게 예측할 수 있도록 다음 분류기에게 가중치(weight)를 부여하면서 학습과 예측을 진행\n",
    "- 스태킹(Stacking) : 양상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수를 사용하는 대신 취합하는 모델을 훈련하여 진행\n",
    " - 예측을 입력으로 받아 최종 예측하는 예측기를 블렌더(blender) 또는 메타학습기(meta learner)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMViLeDq3ctc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    " <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FbCmIoE%2Fbtqy0RW3DBW%2Fcu6uK7BXlJ5KBUZSmz7R0K%2Fimg.png\" alt=\"보팅과 배깅\" width=\"60%\" />\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reVs1Rjw5AVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "보팅 유형 - 하드 보팅(Hard Voting)과 소프트 보팅(Soft Voting)\n",
    "\n",
    "<center>\n",
    " <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FbBEckS%2Fbtqy1I6b5Nk%2FH9U9w6fVBCvsY8PX8F2Zok%2Fimg.png\" alt=\"보팅 유형\" width=\"60%\" />\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxvvu36u5Xou",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 보팅 분류기(Voting Classifier)\n",
    "\n",
    "[VotingClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1596975663707,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "VTGa4RHo5pG9",
    "outputId": "77052a4e-4512-4332-a26d-3544d7065418",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 모듈과 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1596975664010,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "lAnh9RZq5v5a",
    "outputId": "30bdbe85-833f-4302-c5ae-35aa6be49558",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보팅 분류기의 정확도:  0.9474\n",
      "LogisticRegression 정확도: 0.9386\n",
      "KNeighborsClassifier 정확도: 0.9386\n"
     ]
    }
   ],
   "source": [
    "# 보팅 적용을 위한 개별 모델은 로지스틱 회귀와 KNN입니다.\n",
    "logistic_regression = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별모델을 소프트보팅 기반의 앙상블 모델로 구현한 분류기\n",
    "voting_model = VotingClassifier(estimators=[ ('LogisticRegression', logistic_regression),\n",
    "                                            ('KNN', knn) ], voting='soft')\n",
    "\n",
    "# 데이터를 훈련셋과 테스트셋으로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,\n",
    "                                                    cancer.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=156)\n",
    "\n",
    "# 보팅 분류기의 학습/예측/평가\n",
    "voting_model.fit(X_train, y_train)\n",
    "pred = voting_model.predict(X_test)\n",
    "print('보팅 분류기의 정확도: {0: .4f}'.format(accuracy_score(y_test, pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가\n",
    "classifiers = [logistic_regression, knn]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNZrFMtn5-55",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 보팅 분류기의 정확도가 각 개별 모델의 정확도보다 조금 높게 나타남\n",
    "- 여러 알고리즘을 결합한다고 항상 성능이 향상되는 것은 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItTUCyMpgWEh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 랜덤 포레스트\n",
    "\n",
    "- 결정트리의 단점 : 과적합 문제\n",
    "\n",
    "- 현재의 랜덤포레스트 개념은 2001년 레오 브레이먼에 의해 만들어짐\n",
    "\n",
    "- 분류 및 회귀 분석에 사용되는 앙상블 학습 방법의 일종으로 훈련 과정에서 구성한 다수의 결정 트리(Forest)들을 임의적(Random)으로 학습하여 분류 또는 평균 예측(회귀 분석)를 출력\n",
    "\n",
    "- 다수의 결정트리를 구성하는 학습단계와 입력 벡터가 들어왔을 때 분류하거나 예측하는 테스트 단계로 구성\n",
    "\n",
    "- 각각의 트리가 독립적으로 학습하므로 학습 과정을 병렬화할 수 있음\n",
    "\n",
    "- 일반적으로 의사결정트리보다 성능이 좋으며 (Tree Correlation 문제 해결) 파라미터 수가 적어 튜닝도 비교적 간단함\n",
    "\n",
    " - Tree Correlation 문제 : 특정 feature가 정답에 많은 영향을 줄 때 모든 tree들이 비슷한 결과를 도출하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9B4uuAwrfoG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 타킷 예측을 잘하고 구별되는 어러 개의 트리를 만들기 위해 무작위성을 부여\n",
    " - 배깅(Bagging)의 대표적인 알고리즘\n",
    "\n",
    "- 랜덤 트리 생성 방법\n",
    "\n",
    "  (1) 트리를 만들 때 사용하는 데이터 포인트를 무작위로 선택하는 방법\n",
    "  \n",
    "  (2) 분할 테스트에서 특성을 무작위로 선택하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isHxndIZkI__",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 랜덤 포레스트 만들기\n",
    "\n",
    "- 랜덤 포레스트 모델을 만들려면 생성할 트리의 개수를 정해야 함 <br>\n",
    " (RandomForestRegressor나 RandomForestClassifier의 n_estimators 매개변수)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLk05braytCE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. 트리를 만들기 위해 먼저 데이터의 부트스트랩 샘플bootstrap sample을 생성\n",
    "\n",
    " - n_samples개의 데이터 포인트 중에서 무작위로 데이터를 n_samples 횟수만큼 반복 추출\n",
    "\n",
    " - 부스스트랩 샘플의 예 ( [‘a’, ‘b’, ‘c’, ‘d’]에서 부트스트랩 샘플을 만든다고 하면)\n",
    "  >  [‘b’, ‘d’, ‘d’, ‘c’] ,  [‘d’, ‘a’, ‘d’, ‘a’], [‘a’, ‘a’, ‘c’, ‘b’] 등\n",
    "\n",
    "  - 배깅(Bagging)은 bootstrap aggregating의 줄임말로 통계학에서는 중복을 허용한 리샘플링(resampling)을 부트스트래핑(bootstrapping)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68IIKR6_yopz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. 생성한 데이터 셋으로 트리를 만듬\n",
    "\n",
    " - 전체 데이터 셋 대상이 아닌 무작위로 선택한 데이터 셋 중에서 최선의 데이터 셋을 찾음\n",
    " - <font color=blue>몇 개의 특성을 고를 지 선택 -> max_features</font>\n",
    " - <font color=blue>몇 개의 트리를 만들 지 선택 -> n_estimators</font>\n",
    " -  max_features=1로 설정하면 트리의 분기는 테스트할 특성을 고를 필요가 없게 되며 무작위로 선택한 특성의 임계값을 찾기만 하면 됨\n",
    "\n",
    " - max_features 값을 크게 하면 랜덤 포레스트의 트리들은 매우 비슷해지고 가장 두드러진 특성을 이용해 데이터에 잘 맞춰짐\n",
    "\n",
    " - max_features를 낮추면 랜덤 포레스트 트리들은 많이 달라지고 각 트리는 데이터에 맞추기 위해 깊이가 깊어지게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzfNaezAygD9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. 모델에 있는 모든 트리의 예측을 만듬\n",
    "\n",
    " -  회귀의 경우에는 이 예측들을 평균하여 최종 예측을 만듬\n",
    " \n",
    " - 분류의 경우는 약한 투표 전략을 사용 -> 각 알고리즘은 가능성 있는 출력 레이블의 확률을 제공함으로써 간접적인 예측하고 트리들이 예측한 확률을 평균내어 가장 높은 확률을 가진 클래스가 예측값이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4rkB7scKp2SH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[RandomForestClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "```\n",
    "RandomForestClassifier(n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_features, max_leaf_nodes, min_impurity_decrease, min_impurity_split, bootstrap, oob_score, n_jobs, random_state, verbose, warm_start, class_weight)\n",
    "```\n",
    "- <font color=blue>n_estimators : 숲의 나무의 수, 생성할 트리의 개수</font>\n",
    "- criterion : 분할 품질을 측정하는 기능 (default : gini)\n",
    "- max_depth : 트리의 최대 깊이\n",
    "- min_samples_split : 내부 노드를 분할하는데 필요한 최소 샘플 수 (default : 2)\n",
    "- min_samples_leaf : 리프 노드에 있어야 할 최소 샘플 수 (default : 1)\n",
    "- min_weight_fraction_leaf : min_sample_leaf와 같지만 가중치가 부여된 샘플 수에서의 비율\n",
    "- <font color=blue>max_features : 각 노드에서 분할에 사용할 특징의 최대 수</font>\n",
    "- max_leaf_nodes : 리프 노드의 최대수\n",
    "- min_impurity_decrease : 최소 불순도\n",
    "- min_impurity_split : 나무 성장을 멈추기 위한 임계치\n",
    "- bootstrap : 부스트랩 사용 여부\n",
    "- oob_score : 일반화 정확도를 줄이기 위해 밖의 샘플 사용 여부\n",
    "- n_jobs :적합성과 예측성을 위해 병렬로 실행할 작업 수\n",
    "- random_state : 난수 seed 설정\n",
    "- verbose : 실행 과정 출력 여부\n",
    "- warm_start : 이전 호출의 솔루션을 재사용하여 합계에 더 많은 견적가를 추가\n",
    "- class_weight : 클래스 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4433,
     "status": "ok",
     "timestamp": 1596975667277,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "SdHqhgs7D2Sq",
    "outputId": "c7dedf41-148a-4343-f70c-d05f5735f055",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4423,
     "status": "ok",
     "timestamp": 1596975667279,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "_4sfPePHn-CZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# 데이터 로드\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4415,
     "status": "ok",
     "timestamp": 1596975667279,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "x--FEOTZJ88X",
    "outputId": "0c732d71-1f6d-42eb-b0fe-48df1ea116fd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PYUalFvnEKYb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 랜덤 포레스트 안에 만들어진 트리는 estimator_ 속성에 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykJ9shA2xJKc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "각 트리에서 학습된 결정 경계와 이를 취합해 만든 결정 경계 시각화\n",
    "\n",
    "- 다섯 개의 랜덤한 결정 트리의 결정 경계와 예측한 확률을 평균내어 만든 결정 경계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6277,
     "status": "ok",
     "timestamp": 1596975669149,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "3Hp_y3tuoAqy",
    "outputId": "cb7473bc-df13-406c-8da9-1665554fa8ea",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 결정 경계 시각화\n",
    "# 다섯 개의 결정트리 결정 경계\n",
    "\n",
    "\n",
    "# 랜덤포레스트로 만들어진 결정경계\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KS5OpScqId6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 랜덤 포레스트는 개개의 트리보다는 덜 과대적합되고 훨씬 좋은 결정 경계를 만들어줌\n",
    "- 실제 애플리케이션에서는 매우 많은 트리를 사용하기 때문에(수백, 수천 개) 더 부드러운 결정 경계가 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s26F4zVyqhCp",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Random Forest 실습 01\n",
    "\n",
    "- 유방암 데이터셋에 100개의 트리로 이뤄진 랜덤 포레스트를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6271,
     "status": "ok",
     "timestamp": 1596975669152,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "__5U7MtsOdWs",
    "outputId": "63ff43eb-cc86-4281-f8ae-b77ccc754a45",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 데이터 로드\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,\n",
    "                                                    cancer.target,\n",
    "                                                    random_state=66)\n",
    "\n",
    "# 모델 학습\n",
    "\n",
    "\n",
    "# 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAsWae4tq703",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 랜덤 포레스트는 아무런 매개변수 튜닝 없이도 선형 모델이나 단일 결정 트리보다 높은 97% 정확도를 냄\n",
    "\n",
    "- 단일 결정 트리에서 한 것처럼 max_features 매개변수를 조정하거나 사전 가지치기를 할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6908,
     "status": "ok",
     "timestamp": 1596975669796,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "dOuzjzv-rDx_",
    "outputId": "ea1c9b3e-4804-433d-9717-4a0d43fc5dff",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-AjxwRtri2w",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 단일 트리의 경우보다 훨씬 많은 특성이 0 이상의 중요도 값을 가짐\n",
    "- 단일 트리의 결과와 마찬가지로 랜덤 포레스트도 “worst radius” 특성이 매우 중요하다고 보지만, 가장 많은 정보를 가진 특성으로는 “worst perimeter”를 선택\n",
    "- 회귀와 분류에 있어서 랜덤 포레스트는 현재 가장 널리 사용되는 머신러닝 알고리즘\n",
    "- 랜덤 포레스트는 성능이 매우 뛰어나고 매개변수 튜닝을 많이 하지 않아도 잘 작동하며 데이터의 스케일을 맞출 필요도 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2hVEoWREnRg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Random Forest 실습 02\n",
    "\n",
    "붓꽃 데이터 랜덤포레스트를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6900,
     "status": "ok",
     "timestamp": 1596975669797,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "HqcYGPvUxEqD",
    "outputId": "9050004c-f1ef-462a-ef46-ad03cf5ba3b5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data,\n",
    "                                                    iris.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=11)\n",
    "\n",
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6892,
     "status": "ok",
     "timestamp": 1596975669798,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "Pf6RpPzqxqIS",
    "outputId": "9f5daca3-23af-42ac-f7bc-40dd6f949dbf",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 평가\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6882,
     "status": "ok",
     "timestamp": 1596975669798,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "bTHPdbvszaoJ",
    "outputId": "e48d6ccb-2bf6-43f5-8271-c60f2fffa368",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8IPdLC2O0Ayo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 랜덤포레스트 성능향상\n",
    "\n",
    "- iris 데이터가 간단하고 size가 작기 때문에 성능향상은 없으나 max_features와 oob_score를 적용해 보고 \n",
    "- 특성 중요도의 변화를 확인해 본다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w5152KD2vgq",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "oob_score\n",
    "\n",
    "- 샘플링에 중복을 허용하는 배깅(Bagging) 방식을 사용하면 어떤 샘플은 여러번 샘플링되고 어떤 것은 전혀 선택되지 않을 수 있음\n",
    "- 평균적으로 각 예측기에 훈련 샘플의 63% 정도만 샘플링\n",
    "- oob(out-of-bag) : 선택되지 않은 훈련 샘플의 나머지 37% <br>\n",
    "(예측기 마다 남겨진 37%는 모두 다름)\n",
    "- oob_score=True로 지정하면 훈련이 끝난 후 자동으로 oob 샘플을 사용해 평가를 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7163,
     "status": "ok",
     "timestamp": 1596975670086,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "lArZcdVc0AS4",
    "outputId": "5357cd49-e0e1-4ce7-e894-bbd185cc370f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "\n",
    "\n",
    "# 평가\n",
    "\n",
    "\n",
    "# 특성 중요도 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_D2m4--kvoyc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 장단점\n",
    "\n",
    "- 결정트리의 단점을 보완하고 장점은 그대로 가지고 있는 모델이어서 별다른 조정 없이도 괜찮을 결과를 만들어낸다.\n",
    "- 트리가 여러 개 만들어지기 때문에 비전문가에게 예측과정을 보여주기는 어렵다.\n",
    "- 랜덤하게 만들어지기 때문에 random_state를 고정해야 같은 결과를 볼 수 있다.\n",
    "- 텍스트 데이터와 같은 희소한 데이터에는 잘 동작하지 않는다.\n",
    "- 큰 데이터 세트에도 잘 동작하지만 훈련과 예측이 상대적으로 느리다.\n",
    "- 트리 개수가 많아질 수록 시간이 더 오래 걸린다.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOFHIa90QFY/HEyBHL3l/CM",
   "collapsed_sections": [],
   "name": "ml_09_지도학습_RandomForest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
